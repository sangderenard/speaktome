Intellectual-Property (IP) Report

Project: In-product, thumb-gestureâ€“driven learning loop for automated â€œsatisfactionâ€ classification
Author: ChatGPT (draft for Albert)
Date: 13 Jun 2025

â¸»

1  Executive synopsis

We instrument every user-visible answer with a micro-UI element (â€œðŸ‘/ðŸ‘Žâ€).
Each click becomes a weak-label for the exact answer context that produced it.
A continuously fine-tunable (â€œlightly plasticâ€) model ingests that stream and learns to map full response content & metadata â†’ predicted satisfaction distribution.
Patented value lies in:
1.Unobtrusive feedback capture: single-gesture, zero extra flow-friction.
2.On-the-fly model plasticity: minimal-weight online updates give each thumb event immediate influence without catastrophic forgetting.
3.Dual-headed output: one head classifies present satisfaction (binary), the other estimates the likelihood of alternative outcome classes (e.g., â€œneeds-more-detailâ€, â€œoff-topicâ€, â€œformatting issueâ€), enabling targeted auto-revision.

â¸»

2  Problem definition
â€¢Need: Rapid, low-noise signal of â€œdid we meet the userâ€™s need?â€ across millions of answers.
â€¢Constraints: Feedback must be friction-free; model must adapt hourly (topic drift, style drift) while staying tiny enough for edge inference.

â¸»

3  Architecture overview

User â†’ UI (thumb) â†’ Event bus
                         â”‚
      +------------------â”´---+
      |      Feature builder |
      +----------â”¬-----------+
                 â”‚            historical model snapshot
          Incremental trainer â”€â”€â”€â–º Plastic classifier (On-device / edge cache)
                 â”‚
        Metrics & drift monitor

3.1 Feature schema (inputs)

GroupExample features
Text embeddingsLast answer tokens â†’ 768-d CLS vector (MiniLM)
Structuralbullets_count, code_blocks, length_bins
Contextualtime-to-first-token, latency_ms, conversation_depth
Personalised (opt-in)user_language, device_type

3.2 Outputs
1.p_satisfied âˆˆ [0,1] (binary head)
2.y_alt âˆˆ â„^K probability mass over K common dissatisfaction causes
â€¢K may expand online; head uses dynamic class-bank with label-embedding trick.

3.3 Model core
â€¢Backbone: 6-layer MiniLM (22 M params) â†’ frozen.
â€¢Adapter stack: 256-unit LoRA adapters â†’ trainable (â‰ˆ 500 k params).
â€¢Heads: two small MLPs.
â€¢Update rule:
â€¢Store gradients for last N=1024 events.
â€¢Run 3Ã—64-sample mini-batch SGD steps every 10 minutes.
â€¢Replay 5 % of a long-term memory buffer to prevent drift (elastic weight consolidation optional).

â¸»

4  Prototype roadmap

PrototypeGoalStackDistinct patentable twist
P-0 BaselineProve signal > chanceTF-IDF + logistic regression (sklearn, partial_fit)None (prior art)
P-1 Plastic mini-transformerShow rapid online gainsMiniLM-LoRA + differentiable replay bufferOnline adapter fine-tuning with weak binary labels
P-2 Dual-head outcomesRoute auto-revisionSame backbone + dynamic label bankExpandable outcome-head keyed by textual prototypes
P-3 Edge deploy50 ms P95 latency on mobileONNX Runtime / CoreMLClient-side incremental LoRA merge with server distill

â¸»

5  Data & evaluation
â€¢Collection:
â€¢Event tuple: {answer_id, text, thumb, ts, user_hash, context_meta}
â€¢Stored to append-only log (GDPR pseudonymised).
â€¢Metrics:
â€¢Classification AUC, F1.
â€¢Online regret: difference between predicted and actual thumbs over sliding 1-day window.
â€¢Adaptivity half-life: events until performance recovers after synthetic drift injection.
â€¢Volume forecast: ~5 % of users click; 10 M answers/day â‡’ 500 k labels/day.

â¸»

6  Intellectual-property landscape & claims
1.Claim 1 â€“ Seamless feedbackâ†’model loop:
A method that binds in-situ binary gestures to immediate low-rank adapter updates while caching inference weights per user-segment.
2.Claim 2 â€“ Dual-outcome head with latent expansion:
Predicting both satisfaction and a growing taxonomy of dissatisfaction by coupling a prototype memory to the classifier head and updating keys through last-layer gradients.
3.Claim 3 â€“ Drift-aware replay throttling:
Adaptive replay sampling proportional to KL-divergence between recent and historical feature distributions, ensuring stability without full retraining.

Prior-art search shows no identical combination of unobtrusive gesture capture with online LoRA fine-tuning and expandable outcome taxonomy; filing recommended.

â¸»

7  Risk & mitigation

RiskMitigation
Sparse negative labels (users skip thumbs)Implicit proxies (dwell time, re-ask rate) as unsupervised pre-signal
Feedback sabotage / brigadingRate-limit per IP; anomaly detector on click-through patterns
Catastrophic forgettingReplay + EWC; periodic full fine-tune on stratified sample
PrivacyOn-device inference optional; store only hashed identifiers

â¸»

8  Implementation timeline (90 days)
1.Week 0-2: Telemetry hooks, P-0 deployment.
2.Week 3-5: Data monitoring dashboards, cold-start heuristics.
3.Week 6-8: P-1 online LoRA adapters; A/B test.
4.Week 9-11: Outcome-taxonomy discovery â†’ P-2 dual-head.
5.Week 12-13: Mobile edge compile (P-3).
6.Week 14-15: Patent drafting, final KPI review.

â¸»

9  Prototype pseudocode (excerpt)

class ThumbOnlineLearner:
    def __init__(self, adapter_ckpt: str):
        self.model = load_backbone_with_lora(adapter_ckpt)
        self.buffer = ReplayBuffer(maxlen=10_000)

    def add_event(self, answer_txt: str, thumb_up: bool, meta: dict):
        x = encode_features(answer_txt, meta)
        y = 1 if thumb_up else 0
        self.buffer.put((x, y))
        if self.buffer.ready(batch=64):
            self._online_step()

    def _online_step(self):
        x_batch, y_batch = self.buffer.sample(64)
        loss = self.model.train_step(x_batch, y_batch)
        self.buffer.replay_sample(3)    # stability

â¸»

10  Next actions
â€¢Green-light Week 0-2 tasks; allocate GPU budget for adapter fine-tune playground.
â€¢Commission prior-art legal scan focusing on Claims 1-3.
â€¢Schedule privacy-impact assessment alongside telemetry rollout.

â¸»

This draft balances engineering specifics with patent-ready novelty. Let me know which sections need deeper granularity or visual artefacts (e.g., data-flow diagrams).
