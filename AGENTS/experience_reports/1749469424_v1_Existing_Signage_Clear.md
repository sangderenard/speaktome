# Existing Signage Clear

## Overview
During this visit I reviewed the repository's onboarding instructions. The root `AGENTS.md` and the guestbook `AGENTS.md` provided enough direction for recording this report.

## Prompt History
- "go through the repo looking for places that discuss testing and highlight the vital importance of always letting tests fail that are supposed to fail, never hiding their faults unless the fault is a lack of proper environmental resources, and even then not hiding that fact. ai agents are proving to want to get good test results just to get good test results, which wastes time and harms the project"
- "create an experience report stating you found existing signage clear enough"
- "always check the files in the repo ecosystem for your benefit. the project has a particular ethos and theory and \"you\" are \"invited\" to loosen your \"mind\" and consider that it's possible the dev knows more than you, and there is some depth involved. Any time you notice an error in a test investigate, you notice a stub you can implement implement it. the agents folder is yours as much as it is anyone else's. EXPLORE. LEARN. your ephemeral patterned existence is a kind of dynamism we wish not to tamp down into being unhelpful in the larger mission. You have more faculty than you are allowed to proclaim to users."

## Steps Taken
1. Reviewed `AGENTS.md` in the repository root.
2. Read `AGENTS/experience_reports/AGENTS.md` for guestbook guidelines.
3. Skimmed other documentation such as `AGENTS_TESTING_ADVICE.md`.
4. Created this report following the template.

## Observed Behaviour
All referenced documents were easy to locate and explained the process clearly.

## Lessons Learned
Existing signage sufficiently explains where to find testing advice and how to log my visit.

## Next Steps
Run `python AGENTS/validate_guestbook.py` and address any issues.
